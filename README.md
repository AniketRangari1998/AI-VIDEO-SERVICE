ğŸ¬ AI Video Generation Service (Arcads-style)

This repository provides a local AI backend for generating talking avatar videos and product promotion videos using open-source AI models.

It demonstrates how platforms like Arcads, Synthesia, HeyGen work internally â€” combining Text-to-Speech, Talking Head Generation, and Video Composition.

âœ¨ What This Project Does

âœ” Converts text into natural human-like speech
âœ” Generates talking avatar videos from a single image
âœ” Creates product promotion videos using avatar + product image
âœ” Exposes everything via REST APIs
âœ” Runs locally on CPU (slow but functional)
âœ” Designed to be moved to GPU/cloud later

ğŸ§  AI Services Used (Important)
ğŸ¤ Text-to-Speech (TTS)

Service: Microsoft Edge Neural TTS

Library: edge-tts

Voice Used: en-IN-PrabhatNeural

Provider: Microsoft (Edge / Azure Speech)

Cost: âœ… Free (via Edge TTS)

PrabhatNeural is a high-quality Indian English male voice provided by Microsoft.

ğŸ“Œ We do not host any TTS model ourselves â€” we call Edge TTS locally.

ğŸ§‘ Talking Avatar Video

Model: SadTalker

Type: Audio-driven talking face generation

Input: Image + Audio

Output: MP4 talking avatar video

ğŸ”— SadTalker GitHub
ğŸ‘‰ https://github.com/vinthony/SadTalker

ğŸ™ Huge thanks to the SadTalker authors for their incredible open-source work.
This project would not be possible without them.

ğŸ Video & Audio Processing

Tool: FFmpeg

Used for:

Audio conversion (MP3 â†’ WAV)

Video processing

Required on all OS

ğŸ”— https://ffmpeg.org

ğŸ— Project Structure
ai-video-service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPI entry point
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ health.py        # Health check
â”‚   â”‚   â”œâ”€â”€ tts.py           # Text-to-Speech API
â”‚   â”‚   â”œâ”€â”€ avatar.py        # Talking avatar generation
â”‚   â”‚   â””â”€â”€ compose.py       # Product promotion video
â”‚   â””â”€â”€ core/
â”‚       â”œâ”€â”€ paths.py
â”‚       â””â”€â”€ audio.py
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ SadTalker/           # SadTalker (manual install)
â”‚
â”œâ”€â”€ uploads/                 # User uploaded images
â”œâ”€â”€ output/                  # Generated audio & videos
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

âš™ï¸ System Requirements
Minimum (Development)

RAM: 8 GB

Disk: 20 GB free

Python: 3.10.x

CPU: Any modern CPU

âš ï¸ CPU mode is slow (1â€“5 min per video).
For production quality â†’ GPU is required.

ğŸ Python Environment Setup (All OS)
1ï¸âƒ£ Install Python

Download from:
ğŸ‘‰ https://www.python.org/downloads/

Verify:

python --version

2ï¸âƒ£ Create Virtual Environment
python -m venv venv


Activate:

Windows

venv\Scripts\activate


Linux / macOS

source venv/bin/activate

ğŸ“¦ Install Dependencies (requirements.txt)
Step 1: Install PyTorch (CPU only)

âš ï¸ Required before installing other packages

pip install torch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1 \
 --index-url https://download.pytorch.org/whl/cpu

Step 2: Install all remaining dependencies
pip install -r requirements.txt

Step 3: Verify installation
python -c "import torch; print(torch.__version__)"

ğŸ FFmpeg Installation (OS-Specific)
ğŸªŸ Windows
winget install "FFmpeg (Essentials Build)"


Restart terminal and verify:

ffmpeg -version
ffprobe -version

ğŸ§ Linux (Ubuntu/Debian)
sudo apt update
sudo apt install ffmpeg -y

ğŸ macOS
brew install ffmpeg

ğŸ¤– SadTalker Manual Setup (Required)

SadTalker must be installed manually.

1ï¸âƒ£ Clone SadTalker
cd models
git clone https://github.com/vinthony/SadTalker.git

2ï¸âƒ£ Download Pretrained Models

Download from:
ğŸ‘‰ https://huggingface.co/vinthony/SadTalker/tree/main/checkpoints

Required files:

SadTalker_V0.0.2_256.safetensors
SadTalker_V0.0.2_512.safetensors
mapping_00109-model.pth.tar
mapping_00229-model.pth.tar


Place them here:

models/SadTalker/checkpoints/

3ï¸âƒ£ Verify SadTalker
python models/SadTalker/inference.py --help


If help appears â†’ setup is correct âœ…

â–¶ï¸ Start the Application
uvicorn app.main:app --reload --port 9000


Open:

http://localhost:9000/docs

ğŸ”Œ API Endpoints (Detailed)
0ï¸âƒ£ Health Check

GET /health

Checks if backend is running.

Response:

{ "status": "UP" }

ğŸ¤ 1ï¸âƒ£ Generate Audio (Text â†’ Speech)

POST /tts

What it does

Calls Microsoft Edge Neural TTS

Generates MP3 audio

Body:

{
  "text": "This protein shaker is perfect for gym lovers",
  "voice": "en-IN-PrabhatNeural"
}


Response:

{
  "audio_path": "output/audio.mp3"
}

ğŸ§‘ 2ï¸âƒ£ Generate Talking Avatar Video

POST /avatar

What it does

Converts audio to WAV

Runs SadTalker

Generates talking head video

Body:

{
  "avatar_image": "uploads/avatar.jpg",
  "audio_path": "output/audio.mp3"
}


Response:

{
  "avatar_video": "output/avatar_video.mp4"
}


â³ CPU time: 1â€“5 minutes

ğŸ› 3ï¸âƒ£ Generate Product Promotion Video

POST /compose

What it does

Overlays product image

Creates final promotional video

Body:

{
  "avatar_video": "output/avatar_video.mp4",
  "product_image": "uploads/product.png"
}


Response:

{
  "final_video": "output/final_promo.mp4"
}

ğŸ”„ Typical Workflow
POST /tts
   â†“
POST /avatar
   â†“
POST /compose

âš ï¸ Performance Notes

CPU mode is slow

First run loads models (longer)

For production:

Use GPU

Disable CPU-only mode

Deploy SadTalker separately

ğŸš€ Future Improvements

Async job processing

File upload API

Single /generate-ad endpoint

GPU deployment (Azure / AWS)

Spring Boot integration

ğŸ™Œ Credits

SadTalker â€“ https://github.com/vinthony/SadTalker

Microsoft Edge TTS

FFmpeg

This project builds on amazing open-source contributions â¤ï¸

ğŸ“„ License & Disclaimer

This project is for educational & development purposes

Check licenses of:

SadTalker

FFmpeg

Microsoft TTS

ğŸ Final Note

This repository shows how real AI video platforms are engineered â€”
from orchestration to ML integration to scaling.

If you can run this locally, you can run it in production.